{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請將 Epoch 加到 500 個，並觀察 learning curve 的走勢\n",
    "2. 請將 Optimizer 換成 SGD，並觀察 learning curve 的走勢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.10\n",
      "  latest version: 4.7.12\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - keras\n",
      "    - tensorflow==1.14.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _tflow_select-2.3.0        |              mkl           2 KB  defaults\n",
      "    absl-py-0.8.1              |           py37_0         158 KB  conda-forge\n",
      "    astor-0.7.1                |             py_0          22 KB  conda-forge\n",
      "    c-ares-1.15.0              |    h516909a_1001         100 KB  conda-forge\n",
      "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
      "    certifi-2019.11.28         |           py37_0         148 KB  conda-forge\n",
      "    gast-0.3.2                 |             py_0          11 KB  conda-forge\n",
      "    google-pasta-0.1.8         |             py_0          42 KB  conda-forge\n",
      "    grpcio-1.23.0              |   py37he9ae1f9_0         1.1 MB  conda-forge\n",
      "    keras-2.3.1                |           py37_0         591 KB  conda-forge\n",
      "    keras-applications-1.0.8   |             py_1          30 KB  conda-forge\n",
      "    keras-preprocessing-1.1.0  |             py_0          33 KB  conda-forge\n",
      "    libgpuarray-0.7.6          |    h14c3975_1003         263 KB  conda-forge\n",
      "    markdown-3.1.1             |             py_0          60 KB  conda-forge\n",
      "    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n",
      "    pygpu-0.7.6                |py37hc1659b7_1000         680 KB  conda-forge\n",
      "    tensorboard-1.14.0         |           py37_0         3.2 MB  conda-forge\n",
      "    tensorflow-1.14.0          |mkl_py37h45c423b_0           4 KB  defaults\n",
      "    tensorflow-base-1.14.0     |mkl_py37h7ce6ba3_0        84.4 MB  defaults\n",
      "    tensorflow-estimator-1.14.0|   py37h5ca1d4c_0         645 KB  conda-forge\n",
      "    termcolor-1.1.0            |             py_2           6 KB  conda-forge\n",
      "    theano-1.0.4               |py37hf484d3e_1000         3.6 MB  conda-forge\n",
      "    werkzeug-0.16.0            |             py_0         259 KB  conda-forge\n",
      "    wrapt-1.11.2               |   py37h516909a_0          46 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        97.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _tflow_select      pkgs/main/linux-64::_tflow_select-2.3.0-mkl\n",
      "  absl-py            conda-forge/linux-64::absl-py-0.8.1-py37_0\n",
      "  astor              conda-forge/noarch::astor-0.7.1-py_0\n",
      "  c-ares             conda-forge/linux-64::c-ares-1.15.0-h516909a_1001\n",
      "  gast               conda-forge/noarch::gast-0.3.2-py_0\n",
      "  google-pasta       conda-forge/noarch::google-pasta-0.1.8-py_0\n",
      "  grpcio             conda-forge/linux-64::grpcio-1.23.0-py37he9ae1f9_0\n",
      "  keras              conda-forge/linux-64::keras-2.3.1-py37_0\n",
      "  keras-applications conda-forge/noarch::keras-applications-1.0.8-py_1\n",
      "  keras-preprocessi~ conda-forge/noarch::keras-preprocessing-1.1.0-py_0\n",
      "  libgpuarray        conda-forge/linux-64::libgpuarray-0.7.6-h14c3975_1003\n",
      "  markdown           conda-forge/noarch::markdown-3.1.1-py_0\n",
      "  pygpu              conda-forge/linux-64::pygpu-0.7.6-py37hc1659b7_1000\n",
      "  tensorboard        conda-forge/linux-64::tensorboard-1.14.0-py37_0\n",
      "  tensorflow         pkgs/main/linux-64::tensorflow-1.14.0-mkl_py37h45c423b_0\n",
      "  tensorflow-base    pkgs/main/linux-64::tensorflow-base-1.14.0-mkl_py37h7ce6ba3_0\n",
      "  tensorflow-estima~ conda-forge/linux-64::tensorflow-estimator-1.14.0-py37h5ca1d4c_0\n",
      "  termcolor          conda-forge/noarch::termcolor-1.1.0-py_2\n",
      "  theano             conda-forge/linux-64::theano-1.0.4-py37hf484d3e_1000\n",
      "  werkzeug           conda-forge/noarch::werkzeug-0.16.0-py_0\n",
      "  wrapt              conda-forge/linux-64::wrapt-1.11.2-py37h516909a_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2019.6.16-hecc5488_0 --> 2019.11.28-hecc5488_0\n",
      "  certifi                                  2019.6.16-py37_1 --> 2019.11.28-py37_0\n",
      "  openssl                                 1.1.1c-h516909a_0 --> 1.1.1d-h516909a_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "keras-2.3.1          | 591 KB    | ##################################### | 100% \n",
      "_tflow_select-2.3.0  | 2 KB      | ##################################### | 100% \n",
      "tensorflow-1.14.0    | 4 KB      | ##################################### | 100% \n",
      "keras-applications-1 | 30 KB     | ##################################### | 100% \n",
      "werkzeug-0.16.0      | 259 KB    | ##################################### | 100% \n",
      "ca-certificates-2019 | 145 KB    | ##################################### | 100% \n",
      "libgpuarray-0.7.6    | 263 KB    | ##################################### | 100% \n",
      "tensorboard-1.14.0   | 3.2 MB    | ##################################### | 100% \n",
      "grpcio-1.23.0        | 1.1 MB    | ##################################### | 100% \n",
      "pygpu-0.7.6          | 680 KB    | ##################################### | 100% \n",
      "keras-preprocessing- | 33 KB     | ##################################### | 100% \n",
      "termcolor-1.1.0      | 6 KB      | ##################################### | 100% \n",
      "gast-0.3.2           | 11 KB     | ##################################### | 100% \n",
      "astor-0.7.1          | 22 KB     | ##################################### | 100% \n",
      "tensorflow-estimator | 645 KB    | ##################################### | 100% \n",
      "absl-py-0.8.1        | 158 KB    | ##################################### | 100% \n",
      "c-ares-1.15.0        | 100 KB    | ##################################### | 100% \n",
      "wrapt-1.11.2         | 46 KB     | ##################################### | 100% \n",
      "theano-1.0.4         | 3.6 MB    | ##################################### | 100% \n",
      "markdown-3.1.1       | 60 KB     | ##################################### | 100% \n",
      "certifi-2019.11.28   | 148 KB    | ##################################### | 100% \n",
      "openssl-1.1.1d       | 2.1 MB    | ##################################### | 100% \n",
      "google-pasta-0.1.8   | 42 KB     | ##################################### | 100% \n",
      "tensorflow-base-1.14 | 84.4 MB   | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -y tensorflow==1.14.0 keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若有 GPU 且想開啟，可設為 \"0\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 120s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 X 與 Y 獨立放進變數\n",
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "# 資料前處理 - 標準化\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "# 將資料從圖形 (RGB) 轉為向量 (Single Vector)\n",
    "x_train = x_train.reshape((len(x_train), -1))\n",
    "x_test = x_test.reshape((len(x_test), -1))\n",
    "\n",
    "# 將目標轉為 one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp():\n",
    "    \"\"\"Code Here\n",
    "    建立你的神經網路\n",
    "    \"\"\"\n",
    "    input_layer = keras.layers.Input([x_train.shape[-1]])\n",
    "    x = keras.layers.Dense(units=512, activation=\"relu\")(input_layer)\n",
    "    x = keras.layers.Dense(units=256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(units=128, activation=\"relu\")(x)\n",
    "    out = keras.layers.Dense(units=10, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model\n",
    "model = build_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compile 模型\n",
    "\"\"\"\n",
    "model.summary()\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 2.2650 - accuracy: 0.1679 - val_loss: 2.2229 - val_accuracy: 0.2046\n",
      "Epoch 2/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 2.1955 - accuracy: 0.2214 - val_loss: 2.1714 - val_accuracy: 0.2358\n",
      "Epoch 3/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 2.1470 - accuracy: 0.2444 - val_loss: 2.1254 - val_accuracy: 0.2573\n",
      "Epoch 4/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 2.1039 - accuracy: 0.2605 - val_loss: 2.0857 - val_accuracy: 0.2694\n",
      "Epoch 5/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 2.0667 - accuracy: 0.2739 - val_loss: 2.0524 - val_accuracy: 0.2800\n",
      "Epoch 6/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 2.0357 - accuracy: 0.2856 - val_loss: 2.0232 - val_accuracy: 0.2900\n",
      "Epoch 7/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 2.0083 - accuracy: 0.2958 - val_loss: 1.9985 - val_accuracy: 0.3008\n",
      "Epoch 8/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.9846 - accuracy: 0.3030 - val_loss: 1.9759 - val_accuracy: 0.3047\n",
      "Epoch 9/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.9638 - accuracy: 0.3095 - val_loss: 1.9576 - val_accuracy: 0.3077\n",
      "Epoch 10/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.9458 - accuracy: 0.3155 - val_loss: 1.9404 - val_accuracy: 0.3190\n",
      "Epoch 11/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.9297 - accuracy: 0.3212 - val_loss: 1.9261 - val_accuracy: 0.3195\n",
      "Epoch 12/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.9154 - accuracy: 0.3266 - val_loss: 1.9124 - val_accuracy: 0.3249\n",
      "Epoch 13/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.9026 - accuracy: 0.3313 - val_loss: 1.9003 - val_accuracy: 0.3320\n",
      "Epoch 14/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.8909 - accuracy: 0.3365 - val_loss: 1.8895 - val_accuracy: 0.3349\n",
      "Epoch 15/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.8801 - accuracy: 0.3400 - val_loss: 1.8796 - val_accuracy: 0.3379\n",
      "Epoch 16/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.8707 - accuracy: 0.3424 - val_loss: 1.8706 - val_accuracy: 0.3422\n",
      "Epoch 17/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.8614 - accuracy: 0.3467 - val_loss: 1.8619 - val_accuracy: 0.3447\n",
      "Epoch 18/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.8530 - accuracy: 0.3498 - val_loss: 1.8544 - val_accuracy: 0.3460\n",
      "Epoch 19/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.8451 - accuracy: 0.3520 - val_loss: 1.8463 - val_accuracy: 0.3481\n",
      "Epoch 20/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.8376 - accuracy: 0.3554 - val_loss: 1.8396 - val_accuracy: 0.3546\n",
      "Epoch 21/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.8306 - accuracy: 0.3585 - val_loss: 1.8329 - val_accuracy: 0.3527\n",
      "Epoch 22/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.8237 - accuracy: 0.3606 - val_loss: 1.8256 - val_accuracy: 0.3554\n",
      "Epoch 23/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.8170 - accuracy: 0.3623 - val_loss: 1.8214 - val_accuracy: 0.3569\n",
      "Epoch 24/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.8110 - accuracy: 0.3657 - val_loss: 1.8137 - val_accuracy: 0.3612\n",
      "Epoch 25/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.8049 - accuracy: 0.3687 - val_loss: 1.8071 - val_accuracy: 0.3639\n",
      "Epoch 26/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.7989 - accuracy: 0.3701 - val_loss: 1.8035 - val_accuracy: 0.3644\n",
      "Epoch 27/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.7935 - accuracy: 0.3730 - val_loss: 1.7961 - val_accuracy: 0.3676\n",
      "Epoch 28/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7880 - accuracy: 0.3743 - val_loss: 1.7918 - val_accuracy: 0.3725\n",
      "Epoch 29/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.7828 - accuracy: 0.3764 - val_loss: 1.7874 - val_accuracy: 0.3749\n",
      "Epoch 30/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7777 - accuracy: 0.3775 - val_loss: 1.7808 - val_accuracy: 0.3752\n",
      "Epoch 31/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7726 - accuracy: 0.3805 - val_loss: 1.7757 - val_accuracy: 0.3802\n",
      "Epoch 32/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7675 - accuracy: 0.3823 - val_loss: 1.7710 - val_accuracy: 0.3769\n",
      "Epoch 33/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.7627 - accuracy: 0.3833 - val_loss: 1.7674 - val_accuracy: 0.3795\n",
      "Epoch 34/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7580 - accuracy: 0.3862 - val_loss: 1.7627 - val_accuracy: 0.3851\n",
      "Epoch 35/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7535 - accuracy: 0.3877 - val_loss: 1.7571 - val_accuracy: 0.3860\n",
      "Epoch 36/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7488 - accuracy: 0.3901 - val_loss: 1.7540 - val_accuracy: 0.3830\n",
      "Epoch 37/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7444 - accuracy: 0.3902 - val_loss: 1.7504 - val_accuracy: 0.3863\n",
      "Epoch 38/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.7402 - accuracy: 0.3932 - val_loss: 1.7443 - val_accuracy: 0.3867\n",
      "Epoch 39/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7359 - accuracy: 0.3945 - val_loss: 1.7401 - val_accuracy: 0.3892\n",
      "Epoch 40/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7314 - accuracy: 0.3968 - val_loss: 1.7360 - val_accuracy: 0.3926\n",
      "Epoch 41/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7274 - accuracy: 0.3977 - val_loss: 1.7338 - val_accuracy: 0.3950\n",
      "Epoch 42/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7234 - accuracy: 0.3990 - val_loss: 1.7287 - val_accuracy: 0.3968\n",
      "Epoch 43/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7193 - accuracy: 0.4011 - val_loss: 1.7260 - val_accuracy: 0.3933\n",
      "Epoch 44/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7155 - accuracy: 0.4039 - val_loss: 1.7235 - val_accuracy: 0.3968\n",
      "Epoch 45/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7116 - accuracy: 0.4042 - val_loss: 1.7168 - val_accuracy: 0.4004\n",
      "Epoch 46/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.7076 - accuracy: 0.4054 - val_loss: 1.7150 - val_accuracy: 0.3990\n",
      "Epoch 47/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7041 - accuracy: 0.4072 - val_loss: 1.7102 - val_accuracy: 0.4049\n",
      "Epoch 48/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7003 - accuracy: 0.4077 - val_loss: 1.7070 - val_accuracy: 0.4017\n",
      "Epoch 49/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6965 - accuracy: 0.4104 - val_loss: 1.7023 - val_accuracy: 0.4066\n",
      "Epoch 50/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6932 - accuracy: 0.4115 - val_loss: 1.6995 - val_accuracy: 0.4076\n",
      "Epoch 51/500\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.6898 - accuracy: 0.4120 - val_loss: 1.6963 - val_accuracy: 0.4082\n",
      "Epoch 52/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.6860 - accuracy: 0.4138 - val_loss: 1.6923 - val_accuracy: 0.4099\n",
      "Epoch 53/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6827 - accuracy: 0.4147 - val_loss: 1.6903 - val_accuracy: 0.4085\n",
      "Epoch 54/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.6793 - accuracy: 0.4165 - val_loss: 1.6861 - val_accuracy: 0.4139\n",
      "Epoch 55/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6760 - accuracy: 0.4166 - val_loss: 1.6825 - val_accuracy: 0.4118\n",
      "Epoch 56/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6726 - accuracy: 0.4184 - val_loss: 1.6807 - val_accuracy: 0.4131\n",
      "Epoch 57/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6695 - accuracy: 0.4200 - val_loss: 1.6769 - val_accuracy: 0.4142\n",
      "Epoch 58/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6662 - accuracy: 0.4208 - val_loss: 1.6736 - val_accuracy: 0.4203\n",
      "Epoch 59/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6629 - accuracy: 0.4216 - val_loss: 1.6709 - val_accuracy: 0.4195\n",
      "Epoch 60/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6598 - accuracy: 0.4234 - val_loss: 1.6677 - val_accuracy: 0.4204\n",
      "Epoch 61/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6567 - accuracy: 0.4244 - val_loss: 1.6649 - val_accuracy: 0.4202\n",
      "Epoch 62/500\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.6535 - accuracy: 0.4249 - val_loss: 1.6626 - val_accuracy: 0.4197\n",
      "Epoch 63/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6505 - accuracy: 0.4258 - val_loss: 1.6584 - val_accuracy: 0.4217\n",
      "Epoch 64/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6475 - accuracy: 0.4283 - val_loss: 1.6604 - val_accuracy: 0.4179\n",
      "Epoch 65/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6447 - accuracy: 0.4282 - val_loss: 1.6542 - val_accuracy: 0.4234\n",
      "Epoch 66/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6415 - accuracy: 0.4294 - val_loss: 1.6500 - val_accuracy: 0.4251\n",
      "Epoch 67/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6388 - accuracy: 0.4308 - val_loss: 1.6484 - val_accuracy: 0.4234\n",
      "Epoch 68/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6356 - accuracy: 0.4328 - val_loss: 1.6480 - val_accuracy: 0.4274\n",
      "Epoch 69/500\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.6329 - accuracy: 0.4332 - val_loss: 1.6456 - val_accuracy: 0.4246\n",
      "Epoch 70/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6302 - accuracy: 0.4332 - val_loss: 1.6403 - val_accuracy: 0.4275\n",
      "Epoch 71/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6273 - accuracy: 0.4334 - val_loss: 1.6398 - val_accuracy: 0.4283\n",
      "Epoch 72/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6244 - accuracy: 0.4351 - val_loss: 1.6367 - val_accuracy: 0.4303\n",
      "Epoch 73/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6218 - accuracy: 0.4360 - val_loss: 1.6337 - val_accuracy: 0.4293\n",
      "Epoch 74/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6190 - accuracy: 0.4367 - val_loss: 1.6324 - val_accuracy: 0.4301\n",
      "Epoch 75/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6164 - accuracy: 0.4385 - val_loss: 1.6304 - val_accuracy: 0.4298\n",
      "Epoch 76/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6140 - accuracy: 0.4394 - val_loss: 1.6264 - val_accuracy: 0.4346\n",
      "Epoch 77/500\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 1.6109 - accuracy: 0.4406 - val_loss: 1.6230 - val_accuracy: 0.4346\n",
      "Epoch 78/500\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.6084 - accuracy: 0.4406 - val_loss: 1.6196 - val_accuracy: 0.4352\n",
      "Epoch 79/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6055 - accuracy: 0.4417 - val_loss: 1.6181 - val_accuracy: 0.4384\n",
      "Epoch 80/500\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.6032 - accuracy: 0.4427 - val_loss: 1.6196 - val_accuracy: 0.4327\n",
      "Epoch 81/500\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.6005 - accuracy: 0.4441 - val_loss: 1.6145 - val_accuracy: 0.4370\n",
      "Epoch 82/500\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.5978 - accuracy: 0.4443 - val_loss: 1.6121 - val_accuracy: 0.4362\n",
      "Epoch 83/500\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.5959 - accuracy: 0.4449 - val_loss: 1.6091 - val_accuracy: 0.4385\n",
      "Epoch 84/500\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.5932 - accuracy: 0.4467 - val_loss: 1.6067 - val_accuracy: 0.4400\n",
      "Epoch 85/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5905 - accuracy: 0.4463 - val_loss: 1.6034 - val_accuracy: 0.4406\n",
      "Epoch 86/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5882 - accuracy: 0.4467 - val_loss: 1.6031 - val_accuracy: 0.4387\n",
      "Epoch 87/500\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.5854 - accuracy: 0.4479 - val_loss: 1.6007 - val_accuracy: 0.4408\n",
      "Epoch 88/500\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.5832 - accuracy: 0.4492 - val_loss: 1.5994 - val_accuracy: 0.4417\n",
      "Epoch 89/500\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.5808 - accuracy: 0.4503 - val_loss: 1.5964 - val_accuracy: 0.4430\n",
      "Epoch 90/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5786 - accuracy: 0.4512 - val_loss: 1.5968 - val_accuracy: 0.4421\n",
      "Epoch 91/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5763 - accuracy: 0.4517 - val_loss: 1.5911 - val_accuracy: 0.4457\n",
      "Epoch 92/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5739 - accuracy: 0.4529 - val_loss: 1.5948 - val_accuracy: 0.4415\n",
      "Epoch 93/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5718 - accuracy: 0.4527 - val_loss: 1.5927 - val_accuracy: 0.4379\n",
      "Epoch 94/500\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.5695 - accuracy: 0.4538 - val_loss: 1.5917 - val_accuracy: 0.4447\n",
      "Epoch 95/500\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.5673 - accuracy: 0.4543 - val_loss: 1.5830 - val_accuracy: 0.4493\n",
      "Epoch 96/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5652 - accuracy: 0.4553 - val_loss: 1.5811 - val_accuracy: 0.4413\n",
      "Epoch 97/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5627 - accuracy: 0.4556 - val_loss: 1.5790 - val_accuracy: 0.4471\n",
      "Epoch 98/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5605 - accuracy: 0.4562 - val_loss: 1.5796 - val_accuracy: 0.4494\n",
      "Epoch 99/500\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.5583 - accuracy: 0.4563 - val_loss: 1.5799 - val_accuracy: 0.4451\n",
      "Epoch 100/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5560 - accuracy: 0.4586 - val_loss: 1.5759 - val_accuracy: 0.4464\n",
      "Epoch 101/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5536 - accuracy: 0.4588 - val_loss: 1.5733 - val_accuracy: 0.4489\n",
      "Epoch 102/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5519 - accuracy: 0.4580 - val_loss: 1.5703 - val_accuracy: 0.4509\n",
      "Epoch 103/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5495 - accuracy: 0.4595 - val_loss: 1.5722 - val_accuracy: 0.4469\n",
      "Epoch 104/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5474 - accuracy: 0.4602 - val_loss: 1.5717 - val_accuracy: 0.4516\n",
      "Epoch 105/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5456 - accuracy: 0.4609 - val_loss: 1.5654 - val_accuracy: 0.4514\n",
      "Epoch 106/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5436 - accuracy: 0.4622 - val_loss: 1.5650 - val_accuracy: 0.4509\n",
      "Epoch 107/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5416 - accuracy: 0.4623 - val_loss: 1.5627 - val_accuracy: 0.4509\n",
      "Epoch 108/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5397 - accuracy: 0.4626 - val_loss: 1.5677 - val_accuracy: 0.4526\n",
      "Epoch 109/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5372 - accuracy: 0.4641 - val_loss: 1.5586 - val_accuracy: 0.4545\n",
      "Epoch 110/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5351 - accuracy: 0.4650 - val_loss: 1.5579 - val_accuracy: 0.4504\n",
      "Epoch 111/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5331 - accuracy: 0.4667 - val_loss: 1.5572 - val_accuracy: 0.4574\n",
      "Epoch 112/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5314 - accuracy: 0.4661 - val_loss: 1.5562 - val_accuracy: 0.4553\n",
      "Epoch 113/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5295 - accuracy: 0.4664 - val_loss: 1.5513 - val_accuracy: 0.4571\n",
      "Epoch 114/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5276 - accuracy: 0.4683 - val_loss: 1.5498 - val_accuracy: 0.4554\n",
      "Epoch 115/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5256 - accuracy: 0.4692 - val_loss: 1.5526 - val_accuracy: 0.4574\n",
      "Epoch 116/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5238 - accuracy: 0.4686 - val_loss: 1.5466 - val_accuracy: 0.4592\n",
      "Epoch 117/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5220 - accuracy: 0.4693 - val_loss: 1.5500 - val_accuracy: 0.4544\n",
      "Epoch 118/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5199 - accuracy: 0.4696 - val_loss: 1.5470 - val_accuracy: 0.4547\n",
      "Epoch 119/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5179 - accuracy: 0.4715 - val_loss: 1.5484 - val_accuracy: 0.4584\n",
      "Epoch 120/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5163 - accuracy: 0.4699 - val_loss: 1.5414 - val_accuracy: 0.4600\n",
      "Epoch 121/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5146 - accuracy: 0.4712 - val_loss: 1.5419 - val_accuracy: 0.4579\n",
      "Epoch 122/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5129 - accuracy: 0.4720 - val_loss: 1.5385 - val_accuracy: 0.4608\n",
      "Epoch 123/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5106 - accuracy: 0.4726 - val_loss: 1.5372 - val_accuracy: 0.4607\n",
      "Epoch 124/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5085 - accuracy: 0.4737 - val_loss: 1.5385 - val_accuracy: 0.4590\n",
      "Epoch 125/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5071 - accuracy: 0.4736 - val_loss: 1.5366 - val_accuracy: 0.4612\n",
      "Epoch 126/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5051 - accuracy: 0.4747 - val_loss: 1.5326 - val_accuracy: 0.4638\n",
      "Epoch 127/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5034 - accuracy: 0.4758 - val_loss: 1.5322 - val_accuracy: 0.4626\n",
      "Epoch 128/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5017 - accuracy: 0.4757 - val_loss: 1.5303 - val_accuracy: 0.4647\n",
      "Epoch 129/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4998 - accuracy: 0.4763 - val_loss: 1.5285 - val_accuracy: 0.4640\n",
      "Epoch 130/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.4985 - accuracy: 0.4769 - val_loss: 1.5275 - val_accuracy: 0.4637\n",
      "Epoch 131/500\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.4963 - accuracy: 0.4772 - val_loss: 1.5266 - val_accuracy: 0.4644\n",
      "Epoch 132/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4948 - accuracy: 0.4780 - val_loss: 1.5377 - val_accuracy: 0.4604\n",
      "Epoch 133/500\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.4933 - accuracy: 0.4788 - val_loss: 1.5241 - val_accuracy: 0.4662\n",
      "Epoch 134/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4910 - accuracy: 0.4795 - val_loss: 1.5217 - val_accuracy: 0.4665\n",
      "Epoch 135/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4894 - accuracy: 0.4797 - val_loss: 1.5207 - val_accuracy: 0.4647\n",
      "Epoch 136/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4878 - accuracy: 0.4808 - val_loss: 1.5220 - val_accuracy: 0.4648\n",
      "Epoch 137/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4860 - accuracy: 0.4812 - val_loss: 1.5191 - val_accuracy: 0.4666\n",
      "Epoch 138/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4847 - accuracy: 0.4818 - val_loss: 1.5163 - val_accuracy: 0.4705\n",
      "Epoch 139/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4826 - accuracy: 0.4820 - val_loss: 1.5197 - val_accuracy: 0.4638\n",
      "Epoch 140/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4810 - accuracy: 0.4834 - val_loss: 1.5147 - val_accuracy: 0.4693\n",
      "Epoch 141/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4793 - accuracy: 0.4829 - val_loss: 1.5151 - val_accuracy: 0.4692\n",
      "Epoch 142/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4779 - accuracy: 0.4835 - val_loss: 1.5116 - val_accuracy: 0.4689\n",
      "Epoch 143/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4758 - accuracy: 0.4848 - val_loss: 1.5115 - val_accuracy: 0.4685\n",
      "Epoch 144/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4746 - accuracy: 0.4847 - val_loss: 1.5105 - val_accuracy: 0.4686\n",
      "Epoch 145/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4729 - accuracy: 0.4851 - val_loss: 1.5119 - val_accuracy: 0.4668\n",
      "Epoch 146/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4712 - accuracy: 0.4864 - val_loss: 1.5086 - val_accuracy: 0.4709\n",
      "Epoch 147/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4694 - accuracy: 0.4877 - val_loss: 1.5089 - val_accuracy: 0.4683\n",
      "Epoch 148/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4681 - accuracy: 0.4862 - val_loss: 1.5066 - val_accuracy: 0.4727\n",
      "Epoch 149/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4662 - accuracy: 0.4868 - val_loss: 1.5049 - val_accuracy: 0.4697\n",
      "Epoch 150/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4647 - accuracy: 0.4891 - val_loss: 1.5097 - val_accuracy: 0.4707\n",
      "Epoch 151/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4633 - accuracy: 0.4892 - val_loss: 1.5041 - val_accuracy: 0.4677\n",
      "Epoch 152/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4618 - accuracy: 0.4896 - val_loss: 1.5015 - val_accuracy: 0.4719\n",
      "Epoch 153/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4600 - accuracy: 0.4906 - val_loss: 1.4996 - val_accuracy: 0.4725\n",
      "Epoch 154/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4588 - accuracy: 0.4892 - val_loss: 1.5012 - val_accuracy: 0.4712\n",
      "Epoch 155/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4571 - accuracy: 0.4912 - val_loss: 1.4998 - val_accuracy: 0.4715\n",
      "Epoch 156/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.4556 - accuracy: 0.4917 - val_loss: 1.4981 - val_accuracy: 0.4726\n",
      "Epoch 157/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4540 - accuracy: 0.4924 - val_loss: 1.4989 - val_accuracy: 0.4704\n",
      "Epoch 158/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.4522 - accuracy: 0.4923 - val_loss: 1.5016 - val_accuracy: 0.4706\n",
      "Epoch 159/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4507 - accuracy: 0.4926 - val_loss: 1.4909 - val_accuracy: 0.4748\n",
      "Epoch 160/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4496 - accuracy: 0.4937 - val_loss: 1.4943 - val_accuracy: 0.4726\n",
      "Epoch 161/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4481 - accuracy: 0.4955 - val_loss: 1.4906 - val_accuracy: 0.4743\n",
      "Epoch 162/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4459 - accuracy: 0.4955 - val_loss: 1.4905 - val_accuracy: 0.4748\n",
      "Epoch 163/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4452 - accuracy: 0.4946 - val_loss: 1.4878 - val_accuracy: 0.4756\n",
      "Epoch 164/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4429 - accuracy: 0.4970 - val_loss: 1.4951 - val_accuracy: 0.4755\n",
      "Epoch 165/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4416 - accuracy: 0.4971 - val_loss: 1.4851 - val_accuracy: 0.4763\n",
      "Epoch 166/500\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4402 - accuracy: 0.4964 - val_loss: 1.4873 - val_accuracy: 0.4753\n",
      "Epoch 167/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4387 - accuracy: 0.4982 - val_loss: 1.4833 - val_accuracy: 0.4809\n",
      "Epoch 168/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4370 - accuracy: 0.4981 - val_loss: 1.4842 - val_accuracy: 0.4743\n",
      "Epoch 169/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4354 - accuracy: 0.4978 - val_loss: 1.4854 - val_accuracy: 0.4761\n",
      "Epoch 170/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.4341 - accuracy: 0.4986 - val_loss: 1.4827 - val_accuracy: 0.4768\n",
      "Epoch 171/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4325 - accuracy: 0.4990 - val_loss: 1.4856 - val_accuracy: 0.4779\n",
      "Epoch 172/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.4311 - accuracy: 0.4995 - val_loss: 1.4798 - val_accuracy: 0.4771\n",
      "Epoch 173/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4301 - accuracy: 0.5005 - val_loss: 1.4771 - val_accuracy: 0.4770\n",
      "Epoch 174/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4279 - accuracy: 0.5012 - val_loss: 1.4761 - val_accuracy: 0.4793\n",
      "Epoch 175/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4267 - accuracy: 0.5019 - val_loss: 1.4753 - val_accuracy: 0.4792\n",
      "Epoch 176/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4253 - accuracy: 0.5017 - val_loss: 1.4752 - val_accuracy: 0.4800\n",
      "Epoch 177/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4239 - accuracy: 0.5022 - val_loss: 1.4744 - val_accuracy: 0.4812\n",
      "Epoch 178/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4225 - accuracy: 0.5027 - val_loss: 1.4735 - val_accuracy: 0.4795\n",
      "Epoch 179/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4207 - accuracy: 0.5039 - val_loss: 1.4790 - val_accuracy: 0.4769\n",
      "Epoch 180/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4195 - accuracy: 0.5046 - val_loss: 1.4765 - val_accuracy: 0.4814\n",
      "Epoch 181/500\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4182 - accuracy: 0.5034 - val_loss: 1.4722 - val_accuracy: 0.4786\n",
      "Epoch 182/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4164 - accuracy: 0.5062 - val_loss: 1.4713 - val_accuracy: 0.4771\n",
      "Epoch 183/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4155 - accuracy: 0.5056 - val_loss: 1.4700 - val_accuracy: 0.4811\n",
      "Epoch 184/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.4136 - accuracy: 0.5068 - val_loss: 1.4669 - val_accuracy: 0.4810\n",
      "Epoch 185/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4121 - accuracy: 0.5059 - val_loss: 1.4688 - val_accuracy: 0.4783\n",
      "Epoch 186/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.4109 - accuracy: 0.5069 - val_loss: 1.4781 - val_accuracy: 0.4786\n",
      "Epoch 187/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4095 - accuracy: 0.5082 - val_loss: 1.4661 - val_accuracy: 0.4825\n",
      "Epoch 188/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4083 - accuracy: 0.5079 - val_loss: 1.4623 - val_accuracy: 0.4841\n",
      "Epoch 189/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.4068 - accuracy: 0.5088 - val_loss: 1.4610 - val_accuracy: 0.4860\n",
      "Epoch 190/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4053 - accuracy: 0.5092 - val_loss: 1.4623 - val_accuracy: 0.4842\n",
      "Epoch 191/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4042 - accuracy: 0.5097 - val_loss: 1.4680 - val_accuracy: 0.4839\n",
      "Epoch 192/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4027 - accuracy: 0.5089 - val_loss: 1.4580 - val_accuracy: 0.4824\n",
      "Epoch 193/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4014 - accuracy: 0.5099 - val_loss: 1.4666 - val_accuracy: 0.4855\n",
      "Epoch 194/500\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.3999 - accuracy: 0.5105 - val_loss: 1.4612 - val_accuracy: 0.4851\n",
      "Epoch 195/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.3981 - accuracy: 0.5124 - val_loss: 1.4578 - val_accuracy: 0.4852\n",
      "Epoch 196/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.3972 - accuracy: 0.5116 - val_loss: 1.4582 - val_accuracy: 0.4794\n",
      "Epoch 197/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.3958 - accuracy: 0.5128 - val_loss: 1.4624 - val_accuracy: 0.4783\n",
      "Epoch 198/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.3943 - accuracy: 0.5139 - val_loss: 1.4673 - val_accuracy: 0.4758\n",
      "Epoch 199/500\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.3926 - accuracy: 0.5124 - val_loss: 1.4668 - val_accuracy: 0.4819\n",
      "Epoch 200/500\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.3912 - accuracy: 0.5136 - val_loss: 1.4590 - val_accuracy: 0.4845\n",
      "Epoch 201/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.3901 - accuracy: 0.5149 - val_loss: 1.4501 - val_accuracy: 0.4851\n",
      "Epoch 202/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.3891 - accuracy: 0.5153 - val_loss: 1.4534 - val_accuracy: 0.4822\n",
      "Epoch 203/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.3874 - accuracy: 0.5155 - val_loss: 1.4522 - val_accuracy: 0.4887\n",
      "Epoch 204/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.3862 - accuracy: 0.5148 - val_loss: 1.4541 - val_accuracy: 0.4835\n",
      "Epoch 205/500\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.3851 - accuracy: 0.5165 - val_loss: 1.4553 - val_accuracy: 0.4841\n",
      "Epoch 206/500\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.3833 - accuracy: 0.5167 - val_loss: 1.4475 - val_accuracy: 0.4872\n",
      "Epoch 207/500\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.3819 - accuracy: 0.5162 - val_loss: 1.4452 - val_accuracy: 0.4878\n",
      "Epoch 208/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.3804 - accuracy: 0.5170 - val_loss: 1.4502 - val_accuracy: 0.4835\n",
      "Epoch 209/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.3795 - accuracy: 0.5173 - val_loss: 1.4447 - val_accuracy: 0.4877\n",
      "Epoch 210/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.3781 - accuracy: 0.5179 - val_loss: 1.4458 - val_accuracy: 0.4868\n",
      "Epoch 211/500\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.3764 - accuracy: 0.5198 - val_loss: 1.4555 - val_accuracy: 0.4877\n",
      "Epoch 212/500\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.3755 - accuracy: 0.5192 - val_loss: 1.4513 - val_accuracy: 0.4826\n",
      "Epoch 213/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.3743 - accuracy: 0.5199 - val_loss: 1.4446 - val_accuracy: 0.4883\n",
      "Epoch 214/500\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.3730 - accuracy: 0.5207 - val_loss: 1.4497 - val_accuracy: 0.4823\n",
      "Epoch 215/500\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.3714 - accuracy: 0.5208 - val_loss: 1.4371 - val_accuracy: 0.4905\n",
      "Epoch 216/500\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.3697 - accuracy: 0.5213 - val_loss: 1.4455 - val_accuracy: 0.4890\n",
      "Epoch 217/500\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.3688 - accuracy: 0.5210 - val_loss: 1.4474 - val_accuracy: 0.4854\n",
      "Epoch 218/500\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.3673 - accuracy: 0.5222 - val_loss: 1.4387 - val_accuracy: 0.4877\n",
      "Epoch 219/500\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.3662 - accuracy: 0.5225 - val_loss: 1.4413 - val_accuracy: 0.4898\n",
      "Epoch 220/500\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.3652 - accuracy: 0.5222 - val_loss: 1.4359 - val_accuracy: 0.4884\n",
      "Epoch 221/500\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.3639 - accuracy: 0.5230 - val_loss: 1.4364 - val_accuracy: 0.4891\n",
      "Epoch 222/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.3622 - accuracy: 0.5245 - val_loss: 1.4424 - val_accuracy: 0.4857\n",
      "Epoch 223/500\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.3612 - accuracy: 0.5241 - val_loss: 1.4324 - val_accuracy: 0.4901\n",
      "Epoch 224/500\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.3598 - accuracy: 0.5246 - val_loss: 1.4344 - val_accuracy: 0.4901\n",
      "Epoch 225/500\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.3585 - accuracy: 0.5247 - val_loss: 1.4328 - val_accuracy: 0.4925\n",
      "Epoch 226/500\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.3575 - accuracy: 0.5263 - val_loss: 1.4391 - val_accuracy: 0.4895\n",
      "Epoch 227/500\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.3558 - accuracy: 0.5257 - val_loss: 1.4314 - val_accuracy: 0.4925\n",
      "Epoch 228/500\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.3546 - accuracy: 0.5264 - val_loss: 1.4314 - val_accuracy: 0.4942\n",
      "Epoch 229/500\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.3538 - accuracy: 0.5270 - val_loss: 1.4350 - val_accuracy: 0.4885\n",
      "Epoch 230/500\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.3523 - accuracy: 0.5273 - val_loss: 1.4329 - val_accuracy: 0.4933\n",
      "Epoch 231/500\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.3511 - accuracy: 0.5279 - val_loss: 1.4272 - val_accuracy: 0.4924\n",
      "Epoch 232/500\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.3496 - accuracy: 0.5283 - val_loss: 1.4386 - val_accuracy: 0.4875\n",
      "Epoch 233/500\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.3489 - accuracy: 0.5282 - val_loss: 1.4292 - val_accuracy: 0.4939\n",
      "Epoch 234/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.3471 - accuracy: 0.5296 - val_loss: 1.4268 - val_accuracy: 0.4923\n",
      "Epoch 235/500\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.3459 - accuracy: 0.5285 - val_loss: 1.4320 - val_accuracy: 0.4904\n",
      "Epoch 236/500\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.3448 - accuracy: 0.5300 - val_loss: 1.4268 - val_accuracy: 0.4954\n",
      "Epoch 237/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.3434 - accuracy: 0.5308 - val_loss: 1.4285 - val_accuracy: 0.4927\n",
      "Epoch 238/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.3418 - accuracy: 0.5313 - val_loss: 1.4209 - val_accuracy: 0.4958\n",
      "Epoch 239/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.3407 - accuracy: 0.5315 - val_loss: 1.4374 - val_accuracy: 0.4910\n",
      "Epoch 240/500\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.3399 - accuracy: 0.5318 - val_loss: 1.4268 - val_accuracy: 0.4973\n",
      "Epoch 241/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.3383 - accuracy: 0.5316 - val_loss: 1.4381 - val_accuracy: 0.4917\n",
      "Epoch 242/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.3370 - accuracy: 0.5325 - val_loss: 1.4225 - val_accuracy: 0.4978\n",
      "Epoch 243/500\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.3358 - accuracy: 0.5337 - val_loss: 1.4275 - val_accuracy: 0.4916\n",
      "Epoch 244/500\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.3345 - accuracy: 0.5334 - val_loss: 1.4187 - val_accuracy: 0.4963\n",
      "Epoch 245/500\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.3329 - accuracy: 0.5347 - val_loss: 1.4203 - val_accuracy: 0.4916\n",
      "Epoch 246/500\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.3318 - accuracy: 0.5346 - val_loss: 1.4219 - val_accuracy: 0.4960\n",
      "Epoch 247/500\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 1.3305 - accuracy: 0.5350 - val_loss: 1.4187 - val_accuracy: 0.4954\n",
      "Epoch 248/500\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 1.3290 - accuracy: 0.5348 - val_loss: 1.4330 - val_accuracy: 0.4909\n",
      "Epoch 249/500\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.3284 - accuracy: 0.5344 - val_loss: 1.4155 - val_accuracy: 0.4980\n",
      "Epoch 250/500\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.3270 - accuracy: 0.5354 - val_loss: 1.4162 - val_accuracy: 0.4978\n",
      "Epoch 251/500\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.3257 - accuracy: 0.5363 - val_loss: 1.4180 - val_accuracy: 0.4978\n",
      "Epoch 252/500\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.3249 - accuracy: 0.5376 - val_loss: 1.4254 - val_accuracy: 0.4916\n",
      "Epoch 253/500\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.3239 - accuracy: 0.5364 - val_loss: 1.4165 - val_accuracy: 0.4972\n",
      "Epoch 254/500\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.3224 - accuracy: 0.5377 - val_loss: 1.4156 - val_accuracy: 0.4973\n",
      "Epoch 255/500\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.3209 - accuracy: 0.5396 - val_loss: 1.4146 - val_accuracy: 0.4957\n",
      "Epoch 256/500\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.3199 - accuracy: 0.5388 - val_loss: 1.4136 - val_accuracy: 0.4926\n",
      "Epoch 257/500\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.3181 - accuracy: 0.5393 - val_loss: 1.4218 - val_accuracy: 0.4967\n",
      "Epoch 258/500\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.3180 - accuracy: 0.5394 - val_loss: 1.4139 - val_accuracy: 0.4994\n",
      "Epoch 259/500\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.3165 - accuracy: 0.5392 - val_loss: 1.4148 - val_accuracy: 0.4998\n",
      "Epoch 260/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.3151 - accuracy: 0.5387 - val_loss: 1.4162 - val_accuracy: 0.4937\n",
      "Epoch 261/500\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.3134 - accuracy: 0.5411 - val_loss: 1.4202 - val_accuracy: 0.4950\n",
      "Epoch 262/500\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.3127 - accuracy: 0.5396 - val_loss: 1.4083 - val_accuracy: 0.4995\n",
      "Epoch 263/500\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.3112 - accuracy: 0.5416 - val_loss: 1.4133 - val_accuracy: 0.5001\n",
      "Epoch 264/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.3100 - accuracy: 0.5420 - val_loss: 1.4207 - val_accuracy: 0.4935\n",
      "Epoch 265/500\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.3088 - accuracy: 0.5416 - val_loss: 1.4096 - val_accuracy: 0.4979\n",
      "Epoch 266/500\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.3081 - accuracy: 0.5435 - val_loss: 1.4072 - val_accuracy: 0.4970\n",
      "Epoch 267/500\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.3072 - accuracy: 0.5428 - val_loss: 1.4031 - val_accuracy: 0.5038\n",
      "Epoch 268/500\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.3051 - accuracy: 0.5433 - val_loss: 1.4106 - val_accuracy: 0.5029\n",
      "Epoch 269/500\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.3039 - accuracy: 0.5444 - val_loss: 1.4072 - val_accuracy: 0.4976\n",
      "Epoch 270/500\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.3033 - accuracy: 0.5449 - val_loss: 1.4048 - val_accuracy: 0.4989\n",
      "Epoch 271/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.3022 - accuracy: 0.5451 - val_loss: 1.4027 - val_accuracy: 0.5013\n",
      "Epoch 272/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.3008 - accuracy: 0.5461 - val_loss: 1.4057 - val_accuracy: 0.5035\n",
      "Epoch 273/500\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.2996 - accuracy: 0.5454 - val_loss: 1.4081 - val_accuracy: 0.4983\n",
      "Epoch 274/500\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.2990 - accuracy: 0.5449 - val_loss: 1.4021 - val_accuracy: 0.5023\n",
      "Epoch 275/500\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.2977 - accuracy: 0.5469 - val_loss: 1.3998 - val_accuracy: 0.5018\n",
      "Epoch 276/500\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.2970 - accuracy: 0.5463 - val_loss: 1.3983 - val_accuracy: 0.4997\n",
      "Epoch 277/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2947 - accuracy: 0.5482 - val_loss: 1.3990 - val_accuracy: 0.5025\n",
      "Epoch 278/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.2938 - accuracy: 0.5469 - val_loss: 1.4031 - val_accuracy: 0.4977\n",
      "Epoch 279/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2927 - accuracy: 0.5484 - val_loss: 1.3999 - val_accuracy: 0.5029\n",
      "Epoch 280/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2916 - accuracy: 0.5478 - val_loss: 1.3979 - val_accuracy: 0.5061\n",
      "Epoch 281/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.2901 - accuracy: 0.5500 - val_loss: 1.3941 - val_accuracy: 0.5021\n",
      "Epoch 282/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.2889 - accuracy: 0.5491 - val_loss: 1.3964 - val_accuracy: 0.5037\n",
      "Epoch 283/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.2878 - accuracy: 0.5489 - val_loss: 1.4074 - val_accuracy: 0.4986\n",
      "Epoch 284/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.2869 - accuracy: 0.5494 - val_loss: 1.3999 - val_accuracy: 0.5018\n",
      "Epoch 285/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.2852 - accuracy: 0.5511 - val_loss: 1.4053 - val_accuracy: 0.5028\n",
      "Epoch 286/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.2845 - accuracy: 0.5510 - val_loss: 1.3944 - val_accuracy: 0.5043\n",
      "Epoch 287/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.2832 - accuracy: 0.5522 - val_loss: 1.3977 - val_accuracy: 0.5016\n",
      "Epoch 288/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.2818 - accuracy: 0.5521 - val_loss: 1.3915 - val_accuracy: 0.5049\n",
      "Epoch 289/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2808 - accuracy: 0.5529 - val_loss: 1.3922 - val_accuracy: 0.5074\n",
      "Epoch 290/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2801 - accuracy: 0.5532 - val_loss: 1.4194 - val_accuracy: 0.4891\n",
      "Epoch 291/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2785 - accuracy: 0.5520 - val_loss: 1.4001 - val_accuracy: 0.4975\n",
      "Epoch 292/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2773 - accuracy: 0.5537 - val_loss: 1.3976 - val_accuracy: 0.5064\n",
      "Epoch 293/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2766 - accuracy: 0.5540 - val_loss: 1.3958 - val_accuracy: 0.5035\n",
      "Epoch 294/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2746 - accuracy: 0.5542 - val_loss: 1.3960 - val_accuracy: 0.5014\n",
      "Epoch 295/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2734 - accuracy: 0.5553 - val_loss: 1.3905 - val_accuracy: 0.5079\n",
      "Epoch 296/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2728 - accuracy: 0.5562 - val_loss: 1.3939 - val_accuracy: 0.5018\n",
      "Epoch 297/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2718 - accuracy: 0.5552 - val_loss: 1.4137 - val_accuracy: 0.4969\n",
      "Epoch 298/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2708 - accuracy: 0.5561 - val_loss: 1.3903 - val_accuracy: 0.5044\n",
      "Epoch 299/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.2692 - accuracy: 0.5562 - val_loss: 1.3898 - val_accuracy: 0.5063\n",
      "Epoch 300/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.2689 - accuracy: 0.5567 - val_loss: 1.4025 - val_accuracy: 0.4996\n",
      "Epoch 301/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2678 - accuracy: 0.5569 - val_loss: 1.3931 - val_accuracy: 0.5050\n",
      "Epoch 302/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2659 - accuracy: 0.5571 - val_loss: 1.3856 - val_accuracy: 0.5062\n",
      "Epoch 303/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2654 - accuracy: 0.5577 - val_loss: 1.3862 - val_accuracy: 0.5065\n",
      "Epoch 304/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2637 - accuracy: 0.5572 - val_loss: 1.4099 - val_accuracy: 0.5025\n",
      "Epoch 305/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2631 - accuracy: 0.5582 - val_loss: 1.3878 - val_accuracy: 0.5082\n",
      "Epoch 306/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2613 - accuracy: 0.5592 - val_loss: 1.3882 - val_accuracy: 0.5042\n",
      "Epoch 307/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2615 - accuracy: 0.5585 - val_loss: 1.3792 - val_accuracy: 0.5088\n",
      "Epoch 308/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2595 - accuracy: 0.5596 - val_loss: 1.3883 - val_accuracy: 0.5069\n",
      "Epoch 309/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2585 - accuracy: 0.5610 - val_loss: 1.3931 - val_accuracy: 0.5018\n",
      "Epoch 310/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2579 - accuracy: 0.5597 - val_loss: 1.3842 - val_accuracy: 0.5063\n",
      "Epoch 311/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2558 - accuracy: 0.5599 - val_loss: 1.3922 - val_accuracy: 0.5041\n",
      "Epoch 312/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2550 - accuracy: 0.5608 - val_loss: 1.3795 - val_accuracy: 0.5108\n",
      "Epoch 313/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2530 - accuracy: 0.5616 - val_loss: 1.3781 - val_accuracy: 0.5117\n",
      "Epoch 314/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2530 - accuracy: 0.5632 - val_loss: 1.3794 - val_accuracy: 0.5055\n",
      "Epoch 315/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2514 - accuracy: 0.5627 - val_loss: 1.3831 - val_accuracy: 0.5063\n",
      "Epoch 316/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2508 - accuracy: 0.5625 - val_loss: 1.3776 - val_accuracy: 0.5075\n",
      "Epoch 317/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2499 - accuracy: 0.5645 - val_loss: 1.3921 - val_accuracy: 0.5043\n",
      "Epoch 318/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2486 - accuracy: 0.5631 - val_loss: 1.3985 - val_accuracy: 0.5031\n",
      "Epoch 319/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2480 - accuracy: 0.5637 - val_loss: 1.3764 - val_accuracy: 0.5091\n",
      "Epoch 320/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2457 - accuracy: 0.5648 - val_loss: 1.3799 - val_accuracy: 0.5119\n",
      "Epoch 321/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2449 - accuracy: 0.5644 - val_loss: 1.3877 - val_accuracy: 0.5059\n",
      "Epoch 322/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2438 - accuracy: 0.5648 - val_loss: 1.3764 - val_accuracy: 0.5118\n",
      "Epoch 323/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2431 - accuracy: 0.5661 - val_loss: 1.3933 - val_accuracy: 0.5006\n",
      "Epoch 324/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2420 - accuracy: 0.5660 - val_loss: 1.3728 - val_accuracy: 0.5108\n",
      "Epoch 325/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2406 - accuracy: 0.5658 - val_loss: 1.3941 - val_accuracy: 0.5015\n",
      "Epoch 326/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.2402 - accuracy: 0.5663 - val_loss: 1.3805 - val_accuracy: 0.5113\n",
      "Epoch 327/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2388 - accuracy: 0.5658 - val_loss: 1.3762 - val_accuracy: 0.5105\n",
      "Epoch 328/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2369 - accuracy: 0.5674 - val_loss: 1.3792 - val_accuracy: 0.5046\n",
      "Epoch 329/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2355 - accuracy: 0.5675 - val_loss: 1.3755 - val_accuracy: 0.5099\n",
      "Epoch 330/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2347 - accuracy: 0.5691 - val_loss: 1.3956 - val_accuracy: 0.5041\n",
      "Epoch 331/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2341 - accuracy: 0.5681 - val_loss: 1.3743 - val_accuracy: 0.5081\n",
      "Epoch 332/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2332 - accuracy: 0.5684 - val_loss: 1.3765 - val_accuracy: 0.5098\n",
      "Epoch 333/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2315 - accuracy: 0.5693 - val_loss: 1.3760 - val_accuracy: 0.5080\n",
      "Epoch 334/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2301 - accuracy: 0.5712 - val_loss: 1.3721 - val_accuracy: 0.5116\n",
      "Epoch 335/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2294 - accuracy: 0.5708 - val_loss: 1.3767 - val_accuracy: 0.5104\n",
      "Epoch 336/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.2291 - accuracy: 0.5711 - val_loss: 1.3727 - val_accuracy: 0.5095\n",
      "Epoch 337/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.2281 - accuracy: 0.5710 - val_loss: 1.3737 - val_accuracy: 0.5144\n",
      "Epoch 338/500\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.2264 - accuracy: 0.5723 - val_loss: 1.3697 - val_accuracy: 0.5122\n",
      "Epoch 339/500\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.2244 - accuracy: 0.5732 - val_loss: 1.3698 - val_accuracy: 0.5135\n",
      "Epoch 340/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.2240 - accuracy: 0.5703 - val_loss: 1.3813 - val_accuracy: 0.5136\n",
      "Epoch 341/500\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.2232 - accuracy: 0.5729 - val_loss: 1.3647 - val_accuracy: 0.5147\n",
      "Epoch 342/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2219 - accuracy: 0.5730 - val_loss: 1.3865 - val_accuracy: 0.5017\n",
      "Epoch 343/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2200 - accuracy: 0.5736 - val_loss: 1.3735 - val_accuracy: 0.5126\n",
      "Epoch 344/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2194 - accuracy: 0.5736 - val_loss: 1.3729 - val_accuracy: 0.5153\n",
      "Epoch 345/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2192 - accuracy: 0.5747 - val_loss: 1.3645 - val_accuracy: 0.5175\n",
      "Epoch 346/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2179 - accuracy: 0.5752 - val_loss: 1.3656 - val_accuracy: 0.5170\n",
      "Epoch 347/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2160 - accuracy: 0.5743 - val_loss: 1.3637 - val_accuracy: 0.5139\n",
      "Epoch 348/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2148 - accuracy: 0.5757 - val_loss: 1.3746 - val_accuracy: 0.5138\n",
      "Epoch 349/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2140 - accuracy: 0.5744 - val_loss: 1.3733 - val_accuracy: 0.5050\n",
      "Epoch 350/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2137 - accuracy: 0.5755 - val_loss: 1.3678 - val_accuracy: 0.5177\n",
      "Epoch 351/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2116 - accuracy: 0.5758 - val_loss: 1.3862 - val_accuracy: 0.5073\n",
      "Epoch 352/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2113 - accuracy: 0.5765 - val_loss: 1.3727 - val_accuracy: 0.5049\n",
      "Epoch 353/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2102 - accuracy: 0.5770 - val_loss: 1.3695 - val_accuracy: 0.5113\n",
      "Epoch 354/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2092 - accuracy: 0.5775 - val_loss: 1.3747 - val_accuracy: 0.5111\n",
      "Epoch 355/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.2073 - accuracy: 0.5781 - val_loss: 1.3663 - val_accuracy: 0.5120\n",
      "Epoch 356/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2065 - accuracy: 0.5795 - val_loss: 1.3652 - val_accuracy: 0.5137\n",
      "Epoch 357/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2053 - accuracy: 0.5798 - val_loss: 1.4057 - val_accuracy: 0.4962\n",
      "Epoch 358/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2043 - accuracy: 0.5788 - val_loss: 1.3833 - val_accuracy: 0.5107\n",
      "Epoch 359/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2045 - accuracy: 0.5792 - val_loss: 1.3718 - val_accuracy: 0.5154\n",
      "Epoch 360/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.2023 - accuracy: 0.5794 - val_loss: 1.3754 - val_accuracy: 0.5062\n",
      "Epoch 361/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2009 - accuracy: 0.5795 - val_loss: 1.3692 - val_accuracy: 0.5148\n",
      "Epoch 362/500\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.2001 - accuracy: 0.5795 - val_loss: 1.3792 - val_accuracy: 0.5026\n",
      "Epoch 363/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.1990 - accuracy: 0.5820 - val_loss: 1.3759 - val_accuracy: 0.5136\n",
      "Epoch 364/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1975 - accuracy: 0.5815 - val_loss: 1.3647 - val_accuracy: 0.5091\n",
      "Epoch 365/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1976 - accuracy: 0.5816 - val_loss: 1.3892 - val_accuracy: 0.5065\n",
      "Epoch 366/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1962 - accuracy: 0.5835 - val_loss: 1.3880 - val_accuracy: 0.5073\n",
      "Epoch 367/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.1950 - accuracy: 0.5825 - val_loss: 1.3926 - val_accuracy: 0.5074\n",
      "Epoch 368/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1941 - accuracy: 0.5836 - val_loss: 1.3635 - val_accuracy: 0.5128\n",
      "Epoch 369/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1914 - accuracy: 0.5832 - val_loss: 1.4111 - val_accuracy: 0.5018\n",
      "Epoch 370/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1918 - accuracy: 0.5830 - val_loss: 1.3573 - val_accuracy: 0.5150\n",
      "Epoch 371/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1897 - accuracy: 0.5850 - val_loss: 1.3631 - val_accuracy: 0.5144\n",
      "Epoch 372/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.1892 - accuracy: 0.5850 - val_loss: 1.3576 - val_accuracy: 0.5172\n",
      "Epoch 373/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1887 - accuracy: 0.5845 - val_loss: 1.3635 - val_accuracy: 0.5191\n",
      "Epoch 374/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1883 - accuracy: 0.5849 - val_loss: 1.3582 - val_accuracy: 0.5139\n",
      "Epoch 375/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1863 - accuracy: 0.5857 - val_loss: 1.3694 - val_accuracy: 0.5157\n",
      "Epoch 376/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1862 - accuracy: 0.5865 - val_loss: 1.3840 - val_accuracy: 0.5097\n",
      "Epoch 377/500\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.1834 - accuracy: 0.5860 - val_loss: 1.3836 - val_accuracy: 0.5128\n",
      "Epoch 378/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1834 - accuracy: 0.5870 - val_loss: 1.3603 - val_accuracy: 0.5155\n",
      "Epoch 379/500\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.1830 - accuracy: 0.5867 - val_loss: 1.3511 - val_accuracy: 0.5186\n",
      "Epoch 380/500\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.1817 - accuracy: 0.5873 - val_loss: 1.3741 - val_accuracy: 0.5107\n",
      "Epoch 381/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1800 - accuracy: 0.5875 - val_loss: 1.3627 - val_accuracy: 0.5187\n",
      "Epoch 382/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1788 - accuracy: 0.5892 - val_loss: 1.3584 - val_accuracy: 0.5162\n",
      "Epoch 383/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1783 - accuracy: 0.5890 - val_loss: 1.3636 - val_accuracy: 0.5107\n",
      "Epoch 384/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1778 - accuracy: 0.5896 - val_loss: 1.3585 - val_accuracy: 0.5126\n",
      "Epoch 385/500\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.1757 - accuracy: 0.5900 - val_loss: 1.3497 - val_accuracy: 0.5209\n",
      "Epoch 386/500\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1744 - accuracy: 0.5895 - val_loss: 1.3611 - val_accuracy: 0.5116\n",
      "Epoch 387/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1737 - accuracy: 0.5902 - val_loss: 1.3585 - val_accuracy: 0.5245\n",
      "Epoch 388/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1731 - accuracy: 0.5909 - val_loss: 1.3737 - val_accuracy: 0.5168\n",
      "Epoch 389/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1708 - accuracy: 0.5917 - val_loss: 1.3581 - val_accuracy: 0.5184\n",
      "Epoch 390/500\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.1697 - accuracy: 0.5927 - val_loss: 1.3628 - val_accuracy: 0.5126\n",
      "Epoch 391/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1692 - accuracy: 0.5926 - val_loss: 1.3540 - val_accuracy: 0.5218\n",
      "Epoch 392/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1678 - accuracy: 0.5921 - val_loss: 1.3472 - val_accuracy: 0.5207\n",
      "Epoch 393/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1670 - accuracy: 0.5913 - val_loss: 1.3667 - val_accuracy: 0.5112\n",
      "Epoch 394/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1659 - accuracy: 0.5918 - val_loss: 1.3461 - val_accuracy: 0.5248\n",
      "Epoch 395/500\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.1648 - accuracy: 0.5932 - val_loss: 1.3934 - val_accuracy: 0.5098\n",
      "Epoch 396/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1633 - accuracy: 0.5939 - val_loss: 1.3762 - val_accuracy: 0.5158\n",
      "Epoch 397/500\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1630 - accuracy: 0.5942 - val_loss: 1.3524 - val_accuracy: 0.5200\n",
      "Epoch 398/500\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.1618 - accuracy: 0.5951 - val_loss: 1.3611 - val_accuracy: 0.5206\n",
      "Epoch 399/500\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1613 - accuracy: 0.5933 - val_loss: 1.3619 - val_accuracy: 0.5188\n",
      "Epoch 400/500\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1596 - accuracy: 0.5955 - val_loss: 1.3476 - val_accuracy: 0.5156\n",
      "Epoch 401/500\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.1590 - accuracy: 0.5946 - val_loss: 1.3870 - val_accuracy: 0.5057\n",
      "Epoch 402/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1578 - accuracy: 0.5944 - val_loss: 1.3928 - val_accuracy: 0.5089\n",
      "Epoch 403/500\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.1570 - accuracy: 0.5963 - val_loss: 1.3537 - val_accuracy: 0.5198\n",
      "Epoch 404/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1550 - accuracy: 0.5963 - val_loss: 1.3501 - val_accuracy: 0.5201\n",
      "Epoch 405/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1546 - accuracy: 0.5982 - val_loss: 1.3467 - val_accuracy: 0.5233\n",
      "Epoch 406/500\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1529 - accuracy: 0.5969 - val_loss: 1.3743 - val_accuracy: 0.5095\n",
      "Epoch 407/500\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1524 - accuracy: 0.5977 - val_loss: 1.3907 - val_accuracy: 0.5047\n",
      "Epoch 408/500\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1507 - accuracy: 0.5982 - val_loss: 1.3640 - val_accuracy: 0.5181\n",
      "Epoch 409/500\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1505 - accuracy: 0.5997 - val_loss: 1.3519 - val_accuracy: 0.5155\n",
      "Epoch 410/500\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.1501 - accuracy: 0.5978 - val_loss: 1.3513 - val_accuracy: 0.5197\n",
      "Epoch 411/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1481 - accuracy: 0.5996 - val_loss: 1.3413 - val_accuracy: 0.5228\n",
      "Epoch 412/500\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.1471 - accuracy: 0.5995 - val_loss: 1.3486 - val_accuracy: 0.5211\n",
      "Epoch 413/500\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1462 - accuracy: 0.6013 - val_loss: 1.3464 - val_accuracy: 0.5237\n",
      "Epoch 414/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1461 - accuracy: 0.6008 - val_loss: 1.3556 - val_accuracy: 0.5135\n",
      "Epoch 415/500\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.1437 - accuracy: 0.6003 - val_loss: 1.3543 - val_accuracy: 0.5204\n",
      "Epoch 416/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1435 - accuracy: 0.6009 - val_loss: 1.3425 - val_accuracy: 0.5230\n",
      "Epoch 417/500\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1414 - accuracy: 0.6011 - val_loss: 1.3523 - val_accuracy: 0.5185\n",
      "Epoch 418/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1415 - accuracy: 0.6005 - val_loss: 1.3787 - val_accuracy: 0.5103\n",
      "Epoch 419/500\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 1.1410 - accuracy: 0.6016 - val_loss: 1.3615 - val_accuracy: 0.5159\n",
      "Epoch 420/500\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.1388 - accuracy: 0.6032 - val_loss: 1.3558 - val_accuracy: 0.5135\n",
      "Epoch 421/500\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.1377 - accuracy: 0.6031 - val_loss: 1.3725 - val_accuracy: 0.5166\n",
      "Epoch 422/500\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.1367 - accuracy: 0.6026 - val_loss: 1.3565 - val_accuracy: 0.5137\n",
      "Epoch 423/500\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.1350 - accuracy: 0.6044 - val_loss: 1.3538 - val_accuracy: 0.5183\n",
      "Epoch 424/500\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1360 - accuracy: 0.6028 - val_loss: 1.3500 - val_accuracy: 0.5195\n",
      "Epoch 425/500\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.1330 - accuracy: 0.6041 - val_loss: 1.4009 - val_accuracy: 0.5052\n",
      "Epoch 426/500\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.1322 - accuracy: 0.6033 - val_loss: 1.3473 - val_accuracy: 0.5258\n",
      "Epoch 427/500\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.1309 - accuracy: 0.6038 - val_loss: 1.3424 - val_accuracy: 0.5221\n",
      "Epoch 428/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1300 - accuracy: 0.6066 - val_loss: 1.3416 - val_accuracy: 0.5217\n",
      "Epoch 429/500\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.1303 - accuracy: 0.6061 - val_loss: 1.3531 - val_accuracy: 0.5225\n",
      "Epoch 430/500\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.1278 - accuracy: 0.6069 - val_loss: 1.3445 - val_accuracy: 0.5238\n",
      "Epoch 431/500\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.1275 - accuracy: 0.6062 - val_loss: 1.3974 - val_accuracy: 0.5120\n",
      "Epoch 432/500\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.1263 - accuracy: 0.6065 - val_loss: 1.3779 - val_accuracy: 0.5134\n",
      "Epoch 433/500\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.1262 - accuracy: 0.6070 - val_loss: 1.3558 - val_accuracy: 0.5142\n",
      "Epoch 434/500\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.1236 - accuracy: 0.6073 - val_loss: 1.3436 - val_accuracy: 0.5187\n",
      "Epoch 435/500\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1226 - accuracy: 0.6073 - val_loss: 1.3922 - val_accuracy: 0.5121\n",
      "Epoch 436/500\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.1225 - accuracy: 0.6080 - val_loss: 1.3724 - val_accuracy: 0.5162\n",
      "Epoch 437/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.1197 - accuracy: 0.6091 - val_loss: 1.3722 - val_accuracy: 0.5114\n",
      "Epoch 438/500\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.1211 - accuracy: 0.6072 - val_loss: 1.3566 - val_accuracy: 0.5206\n",
      "Epoch 439/500\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.1180 - accuracy: 0.6106 - val_loss: 1.3871 - val_accuracy: 0.5111\n",
      "Epoch 440/500\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.1179 - accuracy: 0.6101 - val_loss: 1.3470 - val_accuracy: 0.5222\n",
      "Epoch 441/500\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.1157 - accuracy: 0.6098 - val_loss: 1.3614 - val_accuracy: 0.5128\n",
      "Epoch 442/500\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.1154 - accuracy: 0.6100 - val_loss: 1.3383 - val_accuracy: 0.5230\n",
      "Epoch 443/500\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.1154 - accuracy: 0.6109 - val_loss: 1.3477 - val_accuracy: 0.5236\n",
      "Epoch 444/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.1144 - accuracy: 0.6091 - val_loss: 1.3930 - val_accuracy: 0.5009\n",
      "Epoch 445/500\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.1129 - accuracy: 0.6110 - val_loss: 1.3617 - val_accuracy: 0.5138\n",
      "Epoch 446/500\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.1122 - accuracy: 0.6106 - val_loss: 1.3911 - val_accuracy: 0.5049\n",
      "Epoch 447/500\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.1089 - accuracy: 0.6140 - val_loss: 1.3581 - val_accuracy: 0.5208\n",
      "Epoch 448/500\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.1106 - accuracy: 0.6133 - val_loss: 1.3562 - val_accuracy: 0.5165\n",
      "Epoch 449/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.1082 - accuracy: 0.6131 - val_loss: 1.3520 - val_accuracy: 0.5225\n",
      "Epoch 450/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1070 - accuracy: 0.6142 - val_loss: 1.3671 - val_accuracy: 0.5169\n",
      "Epoch 451/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.1066 - accuracy: 0.6125 - val_loss: 1.3470 - val_accuracy: 0.5199\n",
      "Epoch 452/500\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.1071 - accuracy: 0.6130 - val_loss: 1.3496 - val_accuracy: 0.5208\n",
      "Epoch 453/500\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.1058 - accuracy: 0.6150 - val_loss: 1.3608 - val_accuracy: 0.5137\n",
      "Epoch 454/500\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.1031 - accuracy: 0.6162 - val_loss: 1.3797 - val_accuracy: 0.5110\n",
      "Epoch 455/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.1020 - accuracy: 0.6136 - val_loss: 1.3521 - val_accuracy: 0.5184\n",
      "Epoch 456/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.1018 - accuracy: 0.6144 - val_loss: 1.3390 - val_accuracy: 0.5238\n",
      "Epoch 457/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.1009 - accuracy: 0.6160 - val_loss: 1.3359 - val_accuracy: 0.5267\n",
      "Epoch 458/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.0997 - accuracy: 0.6156 - val_loss: 1.3358 - val_accuracy: 0.5257\n",
      "Epoch 459/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.1022 - accuracy: 0.6156 - val_loss: 1.3597 - val_accuracy: 0.5167\n",
      "Epoch 460/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.0985 - accuracy: 0.6170 - val_loss: 1.3565 - val_accuracy: 0.5219\n",
      "Epoch 461/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.0974 - accuracy: 0.6169 - val_loss: 1.3883 - val_accuracy: 0.5143\n",
      "Epoch 462/500\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.0952 - accuracy: 0.6172 - val_loss: 1.3444 - val_accuracy: 0.5237\n",
      "Epoch 463/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.0951 - accuracy: 0.6187 - val_loss: 1.3993 - val_accuracy: 0.5114\n",
      "Epoch 464/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.0950 - accuracy: 0.6177 - val_loss: 1.3373 - val_accuracy: 0.5288\n",
      "Epoch 465/500\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.0935 - accuracy: 0.6178 - val_loss: 1.3678 - val_accuracy: 0.5162\n",
      "Epoch 466/500\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.0904 - accuracy: 0.6189 - val_loss: 1.3887 - val_accuracy: 0.5150\n",
      "Epoch 467/500\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.0911 - accuracy: 0.6196 - val_loss: 1.3320 - val_accuracy: 0.5263\n",
      "Epoch 468/500\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.0909 - accuracy: 0.6198 - val_loss: 1.4048 - val_accuracy: 0.5043\n",
      "Epoch 469/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.0921 - accuracy: 0.6184 - val_loss: 1.3450 - val_accuracy: 0.5224\n",
      "Epoch 470/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.0902 - accuracy: 0.6210 - val_loss: 1.3439 - val_accuracy: 0.5201\n",
      "Epoch 471/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.0861 - accuracy: 0.6222 - val_loss: 1.3392 - val_accuracy: 0.5257\n",
      "Epoch 472/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.0853 - accuracy: 0.6215 - val_loss: 1.3625 - val_accuracy: 0.5191\n",
      "Epoch 473/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.0846 - accuracy: 0.6210 - val_loss: 1.3504 - val_accuracy: 0.5181\n",
      "Epoch 474/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.0833 - accuracy: 0.6230 - val_loss: 1.3521 - val_accuracy: 0.5203\n",
      "Epoch 475/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.0829 - accuracy: 0.6207 - val_loss: 1.3324 - val_accuracy: 0.5291\n",
      "Epoch 476/500\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.0808 - accuracy: 0.6237 - val_loss: 1.3545 - val_accuracy: 0.5249\n",
      "Epoch 477/500\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.0809 - accuracy: 0.6228 - val_loss: 1.3819 - val_accuracy: 0.5111\n",
      "Epoch 478/500\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.0821 - accuracy: 0.6218 - val_loss: 1.3430 - val_accuracy: 0.5280\n",
      "Epoch 479/500\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.0801 - accuracy: 0.6239 - val_loss: 1.3601 - val_accuracy: 0.5188\n",
      "Epoch 480/500\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.0784 - accuracy: 0.6231 - val_loss: 1.3370 - val_accuracy: 0.5246\n",
      "Epoch 481/500\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.0748 - accuracy: 0.6266 - val_loss: 1.3561 - val_accuracy: 0.5164\n",
      "Epoch 482/500\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.0760 - accuracy: 0.6236 - val_loss: 1.3561 - val_accuracy: 0.5229\n",
      "Epoch 483/500\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.0758 - accuracy: 0.6251 - val_loss: 1.3515 - val_accuracy: 0.5192\n",
      "Epoch 484/500\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.0744 - accuracy: 0.6262 - val_loss: 1.3964 - val_accuracy: 0.5084\n",
      "Epoch 485/500\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.0730 - accuracy: 0.6250 - val_loss: 1.3513 - val_accuracy: 0.5230\n",
      "Epoch 486/500\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.0731 - accuracy: 0.6252 - val_loss: 1.3408 - val_accuracy: 0.5202\n",
      "Epoch 487/500\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.0708 - accuracy: 0.6255 - val_loss: 1.3450 - val_accuracy: 0.5207\n",
      "Epoch 488/500\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.0714 - accuracy: 0.6267 - val_loss: 1.3386 - val_accuracy: 0.5277\n",
      "Epoch 489/500\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.0678 - accuracy: 0.6284 - val_loss: 1.3491 - val_accuracy: 0.5231\n",
      "Epoch 490/500\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.0664 - accuracy: 0.6276 - val_loss: 1.3570 - val_accuracy: 0.5212\n",
      "Epoch 491/500\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.0672 - accuracy: 0.6282 - val_loss: 1.3409 - val_accuracy: 0.5295\n",
      "Epoch 492/500\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.0655 - accuracy: 0.6273 - val_loss: 1.3460 - val_accuracy: 0.5229\n",
      "Epoch 493/500\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.0665 - accuracy: 0.6279 - val_loss: 1.3557 - val_accuracy: 0.5219\n",
      "Epoch 494/500\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.0637 - accuracy: 0.6289 - val_loss: 1.3659 - val_accuracy: 0.5210\n",
      "Epoch 495/500\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.0637 - accuracy: 0.6295 - val_loss: 1.3328 - val_accuracy: 0.5299\n",
      "Epoch 496/500\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.0611 - accuracy: 0.6315 - val_loss: 1.3514 - val_accuracy: 0.5222\n",
      "Epoch 497/500\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.0611 - accuracy: 0.6290 - val_loss: 1.3398 - val_accuracy: 0.5203\n",
      "Epoch 498/500\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.0615 - accuracy: 0.6304 - val_loss: 1.4218 - val_accuracy: 0.5062\n",
      "Epoch 499/500\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.0600 - accuracy: 0.6319 - val_loss: 1.3585 - val_accuracy: 0.5163\n",
      "Epoch 500/500\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.0587 - accuracy: 0.6318 - val_loss: 1.3488 - val_accuracy: 0.5228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f134e484da0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "設定要訓練的 Epoch 數\n",
    "\"\"\"\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=500, \n",
    "          batch_size=256, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(model.history.history)\n",
    "import matplotlib.pyplot as plt\n",
    "# 以視覺畫方式檢視訓練過程\n",
    "\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "\n",
    "train_acc = model.history.history[\"accuracy\"]\n",
    "valid_acc = model.history.history[\"val_accuracy\"]\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
